This is a (partial) reimplementation of latte
(http://www.math.ucdavis.edu/~latte/)
using polylib (http://icps.u-strasbg.fr/polylib/ or
http://www.kotnet.org/~skimo/polylib/).

Next to polylib, it uses NTL (http://shoup.net/ntl/)
Mac users may want to apply NTL_5_3_2.patch

Optionally, PIP (http://www.piplib.org/)
and Omega (http://www.cs.umd.edu/projects/omega/ or 
http://www.liacs.nl/~sverdool/gitweb.cgi?p=omega.git;a=summary)
can be used during enumeration of integer projections.

Both NTL and polylib need to have been compiled with gmp
support.
For NTL this means you have to specify
    NTL_GMP_LIP=on

Suppose you want to put everyting in /opt,
Then you configure/compile polylib using

./configure --with-libgmp=/path/to/gmp --prefix=/opt
make
make install

For NTL,

cd src
./configure NTL_GMP_LIP=on PREFIX=/opt GMP_PREFIX=/path/to/gmp
make
make install

For Omega,

vi -c '/DESTDIR=/|s/=.*$/=\/opt/|wq' Makefile.config
make libomega.a libcode_gen.a
make install

For piplib,

./configure --with-gmp=/path/to/gmp --prefix=/opt
make
make install

Configure this library using

./configure --prefix=/opt --with-polylib=/opt --with-ntl=/opt

or

./configure --prefix=/opt --with-polylib=/opt --with-ntl=/opt --enable-fractional

Then

make
make check
make install

If you want to put any one of these packages in the default location
(typically /usr/local), then the prefix argument can be omitted.
For more information on other arguments,

./configure --help

Please use a version of the PolyLib library that is not
older than August 13th 2004.

The input format of barvinok_enumerate is the same as that
of testehrhart from the PolyLib distribution.
See the PolyLib manual, barvinok_enumerate.c or the
examples in tests/ehrhart/ .

Note that the fractional representation is subject to change.

The library supports three specialization algorithms.
The first performs a direct specialization using a random vector.
The second performs a "depth-first" incremental specialization.
The third performs a "breadth-first" incremental specialization.

The first is usually the fastest, but can fail if the random
vector happens to be chosen incorrectly.
The incremental algorithms should never fail, but can be slower,
in some cases by quite a bit.  The breadth-first version should
be faster than the depth-first version, especially on polytopes
of moderate dimension with a lot of "structure", but can require
more memory.

Sven Verdoolaege <skimo@kotnet.org>
